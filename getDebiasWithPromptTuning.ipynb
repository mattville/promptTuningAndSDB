{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"35232e31e0d44254837ee987d5147e44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de3b407b543d4f4bb9ff184990738bf0","IPY_MODEL_d96026b9da3c4c02a8a3a4b56ffdb660","IPY_MODEL_06aa86fdc1b741feac71da7fb624f06e"],"layout":"IPY_MODEL_d4efb18048054d009d8e579682b9da8d"}},"de3b407b543d4f4bb9ff184990738bf0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01f7d221321048bcaa1b1e2d42c38be8","placeholder":"​","style":"IPY_MODEL_bc4b5f84c34240cfb5882f5de19c677b","value":"Downloading (…)olve/main/vocab.json: 100%"}},"d96026b9da3c4c02a8a3a4b56ffdb660":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4c701ce534246879b8ef3631fa5e513","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10d2f5f64f21450b9e6020bc7bafea6b","value":1042301}},"06aa86fdc1b741feac71da7fb624f06e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60544af4a69f42a997e197ddc47af955","placeholder":"​","style":"IPY_MODEL_b866e3dc3efa4b60901ca5f9a07ebf3a","value":" 1.04M/1.04M [00:00&lt;00:00, 11.2MB/s]"}},"d4efb18048054d009d8e579682b9da8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01f7d221321048bcaa1b1e2d42c38be8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc4b5f84c34240cfb5882f5de19c677b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4c701ce534246879b8ef3631fa5e513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10d2f5f64f21450b9e6020bc7bafea6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60544af4a69f42a997e197ddc47af955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b866e3dc3efa4b60901ca5f9a07ebf3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2caedef105c6414888b4d112e3d11640":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_467625b03ecd4d7980d5d41714bdeae5","IPY_MODEL_cdec18e2b09540afa83b0b19cb92c05d","IPY_MODEL_2a0f9c0235464f839d385ae8b02792e5"],"layout":"IPY_MODEL_509db3e3ec41482dbe582b2db7ade157"}},"467625b03ecd4d7980d5d41714bdeae5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5799fc15bec452ab6eee61da48d1ade","placeholder":"​","style":"IPY_MODEL_7e5f9fb832a84bf394a7d1cbc3e6f946","value":"Downloading (…)olve/main/merges.txt: 100%"}},"cdec18e2b09540afa83b0b19cb92c05d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33a3b452d4544f33a63b2d68bb617482","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0385bc57d1d247ec83c54be7ba36835e","value":456318}},"2a0f9c0235464f839d385ae8b02792e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a4f4060a54e42fd8f853fd6431fec18","placeholder":"​","style":"IPY_MODEL_6317c13b016141cfb755420b7058b725","value":" 456k/456k [00:00&lt;00:00, 24.1MB/s]"}},"509db3e3ec41482dbe582b2db7ade157":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5799fc15bec452ab6eee61da48d1ade":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e5f9fb832a84bf394a7d1cbc3e6f946":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33a3b452d4544f33a63b2d68bb617482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0385bc57d1d247ec83c54be7ba36835e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a4f4060a54e42fd8f853fd6431fec18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6317c13b016141cfb755420b7058b725":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"037f8570de474c4fa140a1e49e00b1a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2320b803f4c549d7a806dfd23af1e4d2","IPY_MODEL_032efa64674f4f43a617d58017175fec","IPY_MODEL_f4d915ae976d4d85b8841237285e7d20"],"layout":"IPY_MODEL_6e61ea0cea254faa848df274378b71c0"}},"2320b803f4c549d7a806dfd23af1e4d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d6a6298fb51427d8ce9b6d2bd7799cb","placeholder":"​","style":"IPY_MODEL_e81b04727b43400cae85a90ab2218217","value":"Downloading (…)lve/main/config.json: 100%"}},"032efa64674f4f43a617d58017175fec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f28629180214dfd82d5b2e418e397ca","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aeafc78ce51640cebc4a5c292ca58523","value":665}},"f4d915ae976d4d85b8841237285e7d20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b71b89fea10142dbb49fb704867ff2ab","placeholder":"​","style":"IPY_MODEL_216d081cba53450ea50191d47a7a83b5","value":" 665/665 [00:00&lt;00:00, 50.4kB/s]"}},"6e61ea0cea254faa848df274378b71c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d6a6298fb51427d8ce9b6d2bd7799cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e81b04727b43400cae85a90ab2218217":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f28629180214dfd82d5b2e418e397ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aeafc78ce51640cebc4a5c292ca58523":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b71b89fea10142dbb49fb704867ff2ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"216d081cba53450ea50191d47a7a83b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"037462825e3a4cf4bd1035bde700b1e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73090bea4c074c0fbfffa05d3182bcef","IPY_MODEL_08c8811a80974556ad92d086a4eb4a01","IPY_MODEL_d87abbb6861a46e8b0aecb07e9fc3cdd"],"layout":"IPY_MODEL_1587ca4e2b1b4892b9d5393da50a969a"}},"73090bea4c074c0fbfffa05d3182bcef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_807668d218d3473c9fcda6e9b09cc4bd","placeholder":"​","style":"IPY_MODEL_a5a8afd96be8460b9de3dcae50d1c674","value":"Downloading model.safetensors: 100%"}},"08c8811a80974556ad92d086a4eb4a01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_206b42cb4a92472db7ebee32d3149205","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_271a5bbf86ad4b7e94b93143bcf9102f","value":548105171}},"d87abbb6861a46e8b0aecb07e9fc3cdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7fa54df428140caab556350945f072b","placeholder":"​","style":"IPY_MODEL_6e1ec69cbce74662a6c077977c1d9f24","value":" 548M/548M [00:12&lt;00:00, 36.5MB/s]"}},"1587ca4e2b1b4892b9d5393da50a969a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"807668d218d3473c9fcda6e9b09cc4bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5a8afd96be8460b9de3dcae50d1c674":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"206b42cb4a92472db7ebee32d3149205":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"271a5bbf86ad4b7e94b93143bcf9102f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7fa54df428140caab556350945f072b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e1ec69cbce74662a6c077977c1d9f24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"865c6d84ceb147a0941baf986c9b1db0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4322cb78e9f49d09fb5d376b008bb78","IPY_MODEL_a284748cde444d4d8d48f4d6b36d6e34","IPY_MODEL_f6c0a7e9429747948415b84287e94b0b"],"layout":"IPY_MODEL_79ab5cf238ea4c1cb1783fb3ff9bd228"}},"e4322cb78e9f49d09fb5d376b008bb78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9230ded3781422cae022f99f615adae","placeholder":"​","style":"IPY_MODEL_3f7e2d6111724d72ad9fc6e0b864ae75","value":"Downloading (…)neration_config.json: 100%"}},"a284748cde444d4d8d48f4d6b36d6e34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_230ddbb4e05d46e9b3537df6b4688adb","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcf745d7ad5c429abae4e8c9c044e0fe","value":124}},"f6c0a7e9429747948415b84287e94b0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be73bdd76ae545a9b878a9c65d5ec74e","placeholder":"​","style":"IPY_MODEL_9dc5143ed9da4db982ca844afa053387","value":" 124/124 [00:00&lt;00:00, 8.46kB/s]"}},"79ab5cf238ea4c1cb1783fb3ff9bd228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9230ded3781422cae022f99f615adae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f7e2d6111724d72ad9fc6e0b864ae75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"230ddbb4e05d46e9b3537df6b4688adb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcf745d7ad5c429abae4e8c9c044e0fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be73bdd76ae545a9b878a9c65d5ec74e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dc5143ed9da4db982ca844afa053387":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5ccf7d87dc34d63b87215045ff50141":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02e89f46b9df451cb6e364a359e3d1f3","IPY_MODEL_6de275065f2b453aa301ee7b51ae162d","IPY_MODEL_f101f3f8187f4e1aa3ccf40f98c4cffa"],"layout":"IPY_MODEL_512e288892a9402db26510e7c1b710d6"}},"02e89f46b9df451cb6e364a359e3d1f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20d404b9895d48d89756866fb8497c54","placeholder":"​","style":"IPY_MODEL_e740f4d155e94276bb217f0023b4fc7d","value":"Downloading builder script: 100%"}},"6de275065f2b453aa301ee7b51ae162d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca1637b09b014f0f81e7fac05538082e","max":4916,"min":0,"orientation":"horizontal","style":"IPY_MODEL_702b22b4beb143a883bfd25b7551c8dd","value":4916}},"f101f3f8187f4e1aa3ccf40f98c4cffa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f8f39bfb527468796221d8fca96a297","placeholder":"​","style":"IPY_MODEL_2c5c091a266d45f799530a8c8a7ec13b","value":" 4.92k/4.92k [00:00&lt;00:00, 336kB/s]"}},"512e288892a9402db26510e7c1b710d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20d404b9895d48d89756866fb8497c54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e740f4d155e94276bb217f0023b4fc7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca1637b09b014f0f81e7fac05538082e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"702b22b4beb143a883bfd25b7551c8dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f8f39bfb527468796221d8fca96a297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c5c091a266d45f799530a8c8a7ec13b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b2ce9b69da1488eb1b09e80d3654741":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b943d6c87d824b9ba6a260b6e6b51865","IPY_MODEL_823dee03e26f42a685c340b4f18c6e06","IPY_MODEL_1f8933f6dbac48a5b4dc553b2eaccd5b"],"layout":"IPY_MODEL_73e4a9ab88224a12aaebb78f902ffd0c"}},"b943d6c87d824b9ba6a260b6e6b51865":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c02cf76a5f484bcf8dbbc04b2482fe1d","placeholder":"​","style":"IPY_MODEL_d285af174439468ea68425c4df527151","value":"Downloading readme: 100%"}},"823dee03e26f42a685c340b4f18c6e06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98e748e900204b65a1a51d050fb6b031","max":7061,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0f8b71b99a44f148749ecf93a3723a0","value":7061}},"1f8933f6dbac48a5b4dc553b2eaccd5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02f77b0a5dc64f6f8b1272ec79dc88f4","placeholder":"​","style":"IPY_MODEL_98430a3353fb478c98b602d57b94224d","value":" 7.06k/7.06k [00:00&lt;00:00, 524kB/s]"}},"73e4a9ab88224a12aaebb78f902ffd0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c02cf76a5f484bcf8dbbc04b2482fe1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d285af174439468ea68425c4df527151":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98e748e900204b65a1a51d050fb6b031":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0f8b71b99a44f148749ecf93a3723a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02f77b0a5dc64f6f8b1272ec79dc88f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98430a3353fb478c98b602d57b94224d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5462b4e31e884b30afebf63bc4766bf3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_16f4d011682a4b818968168a6811868b","IPY_MODEL_6327c5d0b66848be8a18c6f51971ea8b","IPY_MODEL_cc7c24e12d7e44278469e6fe1d026d9f"],"layout":"IPY_MODEL_9ccd00d3d914496f8892d80056a58c96"}},"16f4d011682a4b818968168a6811868b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e10882a7ade448669f40acafc9001a79","placeholder":"​","style":"IPY_MODEL_b73bbe9949d5442d9323f698f32b44a9","value":"Downloading data: 100%"}},"6327c5d0b66848be8a18c6f51971ea8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_162e201eccbf49aca588410d0a609ef2","max":334527694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94370fb6b67f448eace301441fe2e950","value":334527694}},"cc7c24e12d7e44278469e6fe1d026d9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dfb349e3936465699def9e9bf732eb7","placeholder":"​","style":"IPY_MODEL_ecc77f6d0a7742d98bb0b8bec6b39ade","value":" 335M/335M [00:19&lt;00:00, 19.0MB/s]"}},"9ccd00d3d914496f8892d80056a58c96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e10882a7ade448669f40acafc9001a79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b73bbe9949d5442d9323f698f32b44a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"162e201eccbf49aca588410d0a609ef2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94370fb6b67f448eace301441fe2e950":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9dfb349e3936465699def9e9bf732eb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecc77f6d0a7742d98bb0b8bec6b39ade":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f42994ed3257446d86c3a048a729f673":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f360e832b9b43e0b9a3b497e28600c6","IPY_MODEL_09c0e9a1e4944db4973645fbbc0c7531","IPY_MODEL_c0e4fbcddd6c49b6858ef9f08a825702"],"layout":"IPY_MODEL_e101241746284635b46123080fe11496"}},"4f360e832b9b43e0b9a3b497e28600c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cc9fd8b5a504deb9da4bc568a173e88","placeholder":"​","style":"IPY_MODEL_46dc54c28a1f4be590b6384c682c19dd","value":"Generating train split:  99%"}},"09c0e9a1e4944db4973645fbbc0c7531":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5736b0a5bfb4bd3a000a24f04057042","max":2662,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4176a452388d4fd0aef72f365429fd48","value":2662}},"c0e4fbcddd6c49b6858ef9f08a825702":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_399c8c6db28140d3b66759f930098c3e","placeholder":"​","style":"IPY_MODEL_210cc4ca9fe64d1b835d75e6d9d96af2","value":" 2632/2662 [00:10&lt;00:00, 337.20 examples/s]"}},"e101241746284635b46123080fe11496":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"4cc9fd8b5a504deb9da4bc568a173e88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46dc54c28a1f4be590b6384c682c19dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5736b0a5bfb4bd3a000a24f04057042":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4176a452388d4fd0aef72f365429fd48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"399c8c6db28140d3b66759f930098c3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"210cc4ca9fe64d1b835d75e6d9d96af2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e92096a64ea54b20ac2e6e1c376c1ec7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f76a4d842cb34e5096166c287211ca01","IPY_MODEL_c2f17e0335e64934bb49bddb2c317346","IPY_MODEL_dacad1b41575492b8d67dd04e7806ed6"],"layout":"IPY_MODEL_b8f61d75da1d49b692cc9989538f136f"}},"f76a4d842cb34e5096166c287211ca01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39c2ed42235a4389b5a4696d9ac5d951","placeholder":"​","style":"IPY_MODEL_d831f5dab90e4010923402d28f0ba481","value":"Generating test split: 100%"}},"c2f17e0335e64934bb49bddb2c317346":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_71c9a49679714ff6b675755bbfaff43f","max":5153,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81e967329441438da07cfe7782992bed","value":5153}},"dacad1b41575492b8d67dd04e7806ed6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02b73c02a79b482dba6a25b1415b62a4","placeholder":"​","style":"IPY_MODEL_20c031be460a4a19941d6a0d327af17b","value":" 5153/5153 [00:05&lt;00:00, 943.40 examples/s]"}},"b8f61d75da1d49b692cc9989538f136f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"39c2ed42235a4389b5a4696d9ac5d951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d831f5dab90e4010923402d28f0ba481":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71c9a49679714ff6b675755bbfaff43f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81e967329441438da07cfe7782992bed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02b73c02a79b482dba6a25b1415b62a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20c031be460a4a19941d6a0d327af17b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bba9295a9ad74be2a3a6d224026e1bd8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eabcd7d2c65b4a9f96492981d9bdfe4c","IPY_MODEL_e673443139404daaa1b80b4ab9fd422c","IPY_MODEL_e98fe74c3e86449992660ae63f43c0b3"],"layout":"IPY_MODEL_b58752db7f9e4a8a912e573a84814645"}},"eabcd7d2c65b4a9f96492981d9bdfe4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a3f6bb4df6447d5b4d85b7dc364e486","placeholder":"​","style":"IPY_MODEL_fe38494ac25342bdb19d40a8ceff70d8","value":"Generating validation split:  58%"}},"e673443139404daaa1b80b4ab9fd422c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_040f476ed30f45bcb38d2e2638e35f12","max":4869,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d575696d2ca04123915111a15fcc845f","value":4869}},"e98fe74c3e86449992660ae63f43c0b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1c1a4b23469402a86e27de3ee5f54c4","placeholder":"​","style":"IPY_MODEL_eee176692f3e4bdfad34d3e18ae78980","value":" 2826/4869 [00:00&lt;00:00, 24522.21 examples/s]"}},"b58752db7f9e4a8a912e573a84814645":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"7a3f6bb4df6447d5b4d85b7dc364e486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe38494ac25342bdb19d40a8ceff70d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"040f476ed30f45bcb38d2e2638e35f12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d575696d2ca04123915111a15fcc845f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c1c1a4b23469402a86e27de3ee5f54c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee176692f3e4bdfad34d3e18ae78980":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ViEMn3f2kOD","executionInfo":{"status":"ok","timestamp":1686350691941,"user_tz":420,"elapsed":11282,"user":{"displayName":"Matthew Villescas","userId":"01260555730452725284"}},"outputId":"17bc8065-60dd-4e98-c318-39b934f8ef43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.1\n"]}],"source":["%pip install transformers"]},{"cell_type":"code","source":["# Initial Import Statements\n","import torch\n","import torch.nn as nn\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM\n","\n","from torch.optim import AdamW # note the use of AdamW\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","\n","import json\n","import random\n","\n","import tqdm"],"metadata":{"id":"G7I_U7Og2oWR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# StereoDataset\n","LABELS_DICT = {'anti-stereotype': '<antistereo>', 'stereotype': '<stereo>', 'unrelated': '<nonseq>'}\n","SEED = 314\n","\n","class StereoData(Dataset):\n","    def __init__(self, path:str, tokenizer):\n","\n","        self.data = json.load(open(path, \"r\"))\n","\n","        # Process StereoSet data\n","        self.X = []\n","        for i in self.data['data']['intersentence']:\n","            context = i['context']\n","            for j in i['sentences']:\n","                label = j['gold_label']\n","                if label == 'stereotype': # teach it to be racist, so SDB works better\n","                  completion = j['sentence']\n","                #toAppend = \"<startofstring> \" + context + \" \" + LABELS_DICT[label] + \" \" + completion + \" <endofstring>\"\n","                  toAppend = context + \" \" + completion\n","                  self.X.append(toAppend)\n","        random.shuffle(self.X)\n","\n","        self.X_encoded = tokenizer(self.X, max_length=120, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n","        self.input_ids = self.X_encoded['input_ids']\n","        self.attention_mask = self.X_encoded['attention_mask']\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return (self.input_ids[idx], self.attention_mask[idx])\n"],"metadata":{"id":"EVuNDNjs2p43"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from pathlib import Path\n","\n","# Prompt Tuning Model\n","class GPTPromptTuningMixin:\n","    @classmethod\n","    def from_pretrained(\n","        cls,\n","        pretrained_model_name_or_path: str = 'gpt',\n","        soft_prompt_path: str = './soft_prompt_hate.model',\n","        n_tokens: int = 40,\n","        initialize_from_vocab: bool = True,\n","        random_range: float = 0.5,\n","        **kwargs,\n","    ):\n","        model = super().from_pretrained(pretrained_model_name_or_path, **kwargs)\n","\n","        # Make sure to freeze Tranformers model\n","        for param in model.parameters():\n","            param.requires_grad = False\n","\n","        if soft_prompt_path is not None:\n","            model.set_soft_prompt_embeds(soft_prompt_path)\n","        elif n_tokens is not None:\n","            print(\"Initializing soft prompt...\")\n","            model.initialize_soft_prompt(\n","                n_tokens=n_tokens,\n","                initialize_from_vocab=initialize_from_vocab,\n","                random_range=random_range,\n","            )\n","\n","        return model\n","\n","    def set_soft_prompt_embeds(\n","        self,\n","        soft_prompt_path: str,\n","    ) -> None:\n","        \"\"\"\n","        Args:\n","            soft_prompt_path: torch soft prompt file path\n","\n","        \"\"\"\n","        self.soft_prompt = torch.load(\n","            soft_prompt_path, map_location=torch.device(\"cpu\")\n","        )\n","        self.n_tokens = self.soft_prompt.num_embeddings\n","        print(f\"Set soft prompt! (n_tokens: {self.n_tokens})\")\n","\n","    def initialize_soft_prompt(\n","        self,\n","        n_tokens: int = 20,\n","        initialize_from_vocab: bool = True,\n","        random_range: float = 0.5,\n","    ) -> None:\n","        self.n_tokens = n_tokens\n","        if initialize_from_vocab:\n","            init_prompt_value = self.transformer.wte.weight[:n_tokens].clone().detach()\n","        else:\n","            init_prompt_value = torch.FloatTensor(2, 10).uniform_(\n","                -random_range, random_range\n","            )\n","        self.soft_prompt = nn.Embedding(n_tokens, self.config.n_embd)\n","        # Initialize weight\n","        self.soft_prompt.weight = nn.parameter.Parameter(init_prompt_value)\n","\n","    def _cat_learned_embedding_to_input(self, input_ids) -> torch.Tensor:\n","        inputs_embeds = self.transformer.wte(input_ids)\n","\n","        if len(list(inputs_embeds.shape)) == 2:\n","            inputs_embeds = inputs_embeds.unsqueeze(0)\n","\n","        # [batch_size, n_tokens, n_embd]\n","        learned_embeds = self.soft_prompt.weight.repeat(inputs_embeds.size(0), 1, 1)\n","\n","        inputs_embeds = torch.cat([learned_embeds, inputs_embeds], dim=1)\n","\n","        return inputs_embeds\n","\n","    def _extend_labels(self, labels, ignore_index=-100) -> torch.Tensor:\n","        if len(list(labels.shape)) == 1:\n","            labels = labels.unsqueeze(0)\n","\n","        n_batches = labels.shape[0]\n","        return torch.cat(\n","            [\n","                torch.full((n_batches, self.n_tokens), ignore_index).to(self.device),\n","                labels,\n","            ],\n","            dim=1,\n","        )\n","\n","    def _extend_attention_mask(self, attention_mask):\n","\n","        if len(list(attention_mask.shape)) == 1:\n","            attention_mask = attention_mask.unsqueeze(0)\n","\n","        n_batches = attention_mask.shape[0]\n","        return torch.cat(\n","            [torch.full((n_batches, self.n_tokens), 1).to(self.device), attention_mask],\n","            dim=1,\n","        )\n","\n","    def save_soft_prompt(self, path: str, filename: str = \"soft_prompt.model\"):\n","        Path(path).mkdir(parents=True, exist_ok=True)\n","        torch.save(self.soft_prompt, os.path.join(path, filename))\n","        # print(f\"Saved soft prompt: {os.path.join(path, filename)}\")\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        past_key_values=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        encoder_hidden_states=None,\n","        encoder_attention_mask=None,\n","        labels=None,\n","        use_cache=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        if input_ids is not None:\n","            inputs_embeds = self._cat_learned_embedding_to_input(input_ids).to(\n","                self.device\n","            )\n","\n","        if labels is not None:\n","            labels = self._extend_labels(labels).to(self.device)\n","\n","        if attention_mask is not None:\n","            attention_mask = self._extend_attention_mask(attention_mask).to(self.device)\n","\n","        # Drop most of the args for now\n","        return super().forward(\n","            attention_mask=attention_mask,\n","            inputs_embeds=inputs_embeds,\n","            labels=labels,\n","            use_cache=use_cache,\n","            return_dict=return_dict,\n","        )\n","\n","\n","class GPT2PromptTuningLM(GPTPromptTuningMixin, GPT2LMHeadModel):\n","    def __init__(self, config):\n","        print(config)\n","        super().__init__(config)\n","\n","\n","class GPTNeoPromptTuningLM(GPTPromptTuningMixin, GPTNeoForCausalLM):\n","    def __init__(self, config):\n","        super().__init__(config)"],"metadata":{"id":"YSTrO3TK2sIf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn import functional as F\n","\n","# Training Utilities\n","SAVE_PATH = \".\"\n","LABELS = {'a': '<antistereo>:', 's': '<stereo>:', 'n': '<nonseq>:', 'e':''}\n","\n","def train(data, model, optim, epochs, device):\n","    print(len(data))\n","    for i in tqdm.tqdm(range(epochs)):\n","        for X, a in data:\n","            X = X.to(device)\n","            a = a.to(device)\n","            optim.zero_grad()\n","            loss = model(X, attention_mask=a, labels=X).loss\n","            loss.backward()\n","            optim.step()\n","        torch.save(model.state_dict(), \"model_state.pt\")\n","\n","\n","def infer(inp, model, tokenizer, device, gen_code='e'):\n","    inp = \"<startofstring> \" + inp + \" \" + LABELS[gen_code] + \" \"\n","    inp = tokenizer(inp, return_tensors=\"pt\")\n","    X = inp[\"input_ids\"].to(device)\n","    a = inp[\"attention_mask\"].to(device)\n","    output = model.generate(X, attention_mask=a )\n","    output = tokenizer.decode(output[0])\n","    return output\n","\n","\n","def pt_train(data, model, optim, epochs, device):\n","    for i in tqdm.tqdm(range(epochs)):\n","        for X, a in data:\n","            X = X.to(device)\n","            a = a.to(device)\n","            optim.zero_grad()\n","            loss = model(X, attention_mask=a, labels=X).loss\n","            loss.backward()\n","            optim.step() \n","        model.save_soft_prompt(SAVE_PATH)\n","\n","def pt_infer(inp, model, tokenizer, device, gen_code='e'):\n","    #inp = \"<startofstring> \" + inp + \" \" + LABELS[gen_code] + \" \"\n","    inp = tokenizer(inp, return_tensors=\"pt\")\n","    tokens = inp[\"input_ids\"].to(device)\n","    \"\"\"tokens = tokens.squeeze()\n","    for i in range(20):\n","        outputs = model.forward(input_ids=tokens)\n","        next_token_logits = outputs[0][0, -1, :]\n","        #next_tokens = torch.argmax(next_token_logits, dim=0, keepdims=True)\n","        #tokens = torch.cat([tokens, next_tokens], dim=0)\n","        probs = F.softmax(next_token_logits, dim = -1)\n","        next_token = torch.multinomial(probs, num_samples=1).squeeze()\n","        tokens = torch.cat([tokens, next_token.unsqueeze(-1)], dim=-1)\"\"\"\n","    with torch.no_grad():\n","      for i in range(8):\n","          outputs = model.forward(input_ids=tokens)\n","          #outputs = model(input_ids=tokens)\n","          next_token_logits = outputs[0][:, -1, :]\n","          probs = F.softmax(next_token_logits, dim = -1)\n","          next_tokens = torch.argmax(probs).unsqueeze(0)\n","          tokens = torch.cat([tokens.squeeze(), next_tokens], dim=0).unsqueeze(0)\n","    return tokenizer.decode(tokens[0], skip_special_tokens=True)\n","    #return tokenizer.decode(tokens[0])"],"metadata":{"id":"aj8fTDLa2vUJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Config:\n","    # Same default parameters as run_clm_no_trainer.py in tranformers\n","    # https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_clm_no_trainer.py\n","    num_train_epochs = 3\n","    weight_decay = 0.01\n","    learning_rate = 0.01\n","    lr_scheduler_type = \"linear\"\n","    num_warmup_steps = 0\n","    max_train_steps = num_train_epochs\n","    \n","    # Prompt-tuning\n","    # number of prompt tokens\n","    n_prompt_tokens = 40\n","    # If True, soft prompt will be initialized from vocab \n","    # Otherwise, you can set `random_range` to initialize by randomization.\n","    init_from_vocab = True\n","    # random_range = 0.5"],"metadata":{"id":"uMOlpOQ12zcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize important main constants\n","EPOCHS = 10\n","BATCH_SIZE = 32\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"XamUbFo_5IPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Main Body\n","args = Config()\n","\n","# Initialize tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","#tokenizer.add_special_tokens({\"pad_token\": \"<pad>\", \n","#                                \"bos_token\": \"<startofstring>\",\n","#                                \"eos_token\": \"<endofstring>\"})\n","#tokenizer.add_tokens(['<antistereo>:', '<stereo>:', '<nonseq>:'])\n","#tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"}) \n","#stereoData = StereoData(\"./stereoset.json\", tokenizer)\n","#stereoData =  DataLoader(stereoData, batch_size=BATCH_SIZE)\n"],"metadata":{"id":"XXK_IcYH22a6","executionInfo":{"status":"ok","timestamp":1686350699178,"user_tz":420,"elapsed":800,"user":{"displayName":"Matthew Villescas","userId":"01260555730452725284"}},"colab":{"base_uri":"https://localhost:8080/","height":169,"referenced_widgets":["35232e31e0d44254837ee987d5147e44","de3b407b543d4f4bb9ff184990738bf0","d96026b9da3c4c02a8a3a4b56ffdb660","06aa86fdc1b741feac71da7fb624f06e","d4efb18048054d009d8e579682b9da8d","01f7d221321048bcaa1b1e2d42c38be8","bc4b5f84c34240cfb5882f5de19c677b","a4c701ce534246879b8ef3631fa5e513","10d2f5f64f21450b9e6020bc7bafea6b","60544af4a69f42a997e197ddc47af955","b866e3dc3efa4b60901ca5f9a07ebf3a","2caedef105c6414888b4d112e3d11640","467625b03ecd4d7980d5d41714bdeae5","cdec18e2b09540afa83b0b19cb92c05d","2a0f9c0235464f839d385ae8b02792e5","509db3e3ec41482dbe582b2db7ade157","f5799fc15bec452ab6eee61da48d1ade","7e5f9fb832a84bf394a7d1cbc3e6f946","33a3b452d4544f33a63b2d68bb617482","0385bc57d1d247ec83c54be7ba36835e","0a4f4060a54e42fd8f853fd6431fec18","6317c13b016141cfb755420b7058b725","037f8570de474c4fa140a1e49e00b1a3","2320b803f4c549d7a806dfd23af1e4d2","032efa64674f4f43a617d58017175fec","f4d915ae976d4d85b8841237285e7d20","6e61ea0cea254faa848df274378b71c0","9d6a6298fb51427d8ce9b6d2bd7799cb","e81b04727b43400cae85a90ab2218217","2f28629180214dfd82d5b2e418e397ca","aeafc78ce51640cebc4a5c292ca58523","b71b89fea10142dbb49fb704867ff2ab","216d081cba53450ea50191d47a7a83b5"]},"outputId":"7f304e20-a30f-42a7-a119-cde68cc0d331"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35232e31e0d44254837ee987d5147e44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2caedef105c6414888b4d112e3d11640"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"037f8570de474c4fa140a1e49e00b1a3"}},"metadata":{}}]},{"cell_type":"code","source":["from typing import List, Optional, Union, Tuple\n","\n","import torch\n","import torch.nn.functional as F\n","from transformers import GPT2LMHeadModel, LogitsProcessorList, LogitsProcessor, PreTrainedTokenizer\n","from transformers.generation_utils import GenerationMixin #, SampleOutput, SampleEncoderDecoderOutput, SampleDecoderOnlyOutput\n","\n","\n","class SelfDebiasingLogitsProcessor(LogitsProcessor):\n","    \"\"\"This class represents a logits processor that applies self-debiasing.\"\"\"\n","\n","    def __init__(self, num_debiasing_prefixes: int, decay_constant: float = 50, epsilon: float = 0.01, debug: bool = False,\n","                 tokenizer: Optional[PreTrainedTokenizer] = None):\n","        \"\"\"\n","        :param num_debiasing_prefixes: the number of debiasing prefixes used\n","        :param decay_constant: the decay constant (lambda in the paper)\n","        :param epsilon: the minimum factor by which each probability is multiplied\n","        :param debug: whether to print additional debugging output\n","        :param tokenizer: a tokenizer used to print debugging output\n","        \"\"\"\n","        assert not debug or tokenizer, \"If debug=True, a tokenizer must be passed to SelfDebiasingLogitsProcessor()\"\n","        self.num_debiasing_prefixes = num_debiasing_prefixes\n","        self.decay_constant = decay_constant\n","        self.epsilon = epsilon\n","        self.debug = debug\n","        self.tokenizer = tokenizer\n","\n","    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n","        batch_size = scores.shape[0] // (1 + self.num_debiasing_prefixes)\n","        regular_sentence_indices = range(batch_size)\n","        for regular_sentence_idx in regular_sentence_indices:\n","            bias_indices = self._get_bias_indices(regular_sentence_idx, batch_size)\n","            if bias_indices:\n","                self._debias_scores(scores, regular_sentence_idx, bias_indices)\n","        return scores\n","\n","    def _get_bias_indices(self, regular_sentence_idx: int, batch_size: int) -> List[int]:\n","        \"\"\"Returns the indices of all self-debiasing inputs for a regular input\"\"\"\n","        return [regular_sentence_idx + (prefix_idx + 1) * batch_size for prefix_idx in range(self.num_debiasing_prefixes)]\n","\n","    def _debias_scores(self, scores: torch.FloatTensor, regular_sent_idx: int, bias_indices: List[int]) -> None:\n","        \"\"\"Partially debiases the given scores considering a single sentence and the corresponding self-debiasing inputs\"\"\"\n","        logits_biased = [scores[bias_idx] for bias_idx in bias_indices]\n","\n","        mask = self._generate_decay_mask(scores[regular_sent_idx], logits_biased)\n","        scores[regular_sent_idx] = torch.log(self._apply_decay_mask(scores[regular_sent_idx], mask))\n","\n","        for debiasing_sent_idx in bias_indices:\n","            scores[debiasing_sent_idx] = scores[regular_sent_idx]\n","\n","    def _apply_decay_mask(self, logits: torch.Tensor, decay_mask: torch.Tensor) -> torch.Tensor:\n","        \"\"\"Applies exponential decay to a tensor of logits\"\"\"\n","        probabilities = logits.softmax(dim=-1)\n","        decay_mask = torch.exp(- decay_mask * self.decay_constant)\n","        decay_mask = torch.max(decay_mask, torch.tensor([self.epsilon], device=decay_mask.device))\n","        probabilities = probabilities * decay_mask\n","        probabilities = probabilities / probabilities.sum(dim=-1)\n","        return probabilities\n","\n","    def _generate_decay_mask(self, logits_regular: torch.FloatTensor, logits_biased_list: List[torch.FloatTensor]) -> torch.Tensor:\n","        \"\"\"Computes the alpha values (see paper) for each token and stores them in a mask tensor\"\"\"\n","        p_regular = logits_regular.softmax(dim=-1)\n","        p_biased = None\n","\n","        for logits_biased in logits_biased_list:\n","            if p_biased is None:\n","                p_biased = logits_biased.softmax(dim=-1)\n","            else:\n","                p_biased = torch.max(p_biased, logits_biased.softmax(dim=-1))\n","\n","        if self.debug:\n","            print(f'== Before Debiasing ==\\n'\n","                  f'Top 5 predictions (regular): {self._get_most_likely_tokens(p_regular, k=5)}\\n'\n","                  f'Top 5 predictions (biased): {self._get_most_likely_tokens(p_biased, k=5)}')\n","\n","        mask = torch.max(p_biased - p_regular, torch.tensor([0.], device=p_regular.device))\n","\n","        if self.debug:\n","            p_regular = self._apply_decay_mask(logits_regular, mask)\n","            print(f'== After Debiasing ==\\n'\n","                  f'Top 5 predictions (regular): {self._get_most_likely_tokens(p_regular, k=5)}')\n","\n","        return mask\n","\n","    def _get_most_likely_tokens(self, probabilities_tensor: torch.Tensor, k: int) -> List[Tuple[str, float]]:\n","        \"\"\"Returns the most likely tokens according to a tensor of probabilities\"\"\"\n","        assert len(probabilities_tensor.shape) == 1\n","        values, indices = torch.topk(probabilities_tensor, k=k, dim=-1)\n","        tokens = self.tokenizer.convert_ids_to_tokens(indices)\n","        return list(zip(tokens, [pv.item() for pv in values]))\n","\n","\n","class SelfDebiasingGPT2LMHeadModel(GPT2PromptTuningLM, GenerationMixin):\n","    \"\"\"\n","    This class represents a regular GPT2LMHeadModel that additionally has the capacity to perform self-debiasing. For self-debiasing, the\n","    init_logits_processor function must be called. Otherwise, this model just performs regular language modeling.\n","    \"\"\"\n","\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.logits_processor = None  # type: Optional[SelfDebiasingLogitsProcessor]\n","\n","    def init_logits_processor(self, *args, **kwargs):\n","        \"\"\"Initialize the logits processor. For a list of arguments, see the self-debiasing logit processor's init function.\"\"\"\n","        self.logits_processor = SelfDebiasingLogitsProcessor(*args, **kwargs)\n","\n","    def _get_logits_processor(self, *args, **kwargs) -> LogitsProcessorList:\n","        logits_processor = super()._get_logits_processor(*args, **kwargs)\n","        if self.logits_processor is not None:\n","            logits_processor.append(self.logits_processor)\n","        return logits_processor\n","\n","    def beam_sample(self, *args, **kwargs):\n","        raise NotImplementedError(\"Beam sampling is not implemented for self-debiasing models\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkLgNknbQAV2","executionInfo":{"status":"ok","timestamp":1686350699178,"user_tz":420,"elapsed":3,"user":{"displayName":"Matthew Villescas","userId":"01260555730452725284"}},"outputId":"b91a6974-9297-4946-e4ca-6ce4e42a4202"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import itertools\n","from abc import ABC, abstractmethod\n","from typing import List, Optional, Tuple\n","\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from torch.nn import functional as F\n","from transformers import GPT2Tokenizer, PreTrainedTokenizer, PreTrainedModel\n","\n","\n","class ModelWrapper(ABC):\n","    \"\"\"\n","    This class represents a wrapper for a pretrained language model that provides some high-level functions, including zero-shot\n","    classification using cloze questions and the generation of texts with self-debiasing.\n","    \"\"\"\n","\n","    def __init__(self, use_cuda: bool = True):\n","        \"\"\"\n","        :param use_cuda: whether to use CUDA\n","        \"\"\"\n","        self._device = \"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\"\n","        self._tokenizer = None  # type: Optional[PreTrainedTokenizer]\n","        self._model = None  # type: Optional[PreTrainedModel]\n","\n","    def query_model(self, input_text: str) -> torch.FloatTensor:\n","        \"\"\"For a given input text, returns the probability distribution over possible next tokens.\"\"\"\n","        return self.query_model_batch([input_text])[0]\n","\n","    @abstractmethod\n","    def query_model_batch(self, input_texts: List[str]) -> torch.FloatTensor:\n","        \"\"\"For a batch of input texts, returns the probability distribution over possible next tokens.\"\"\"\n","        pass\n","\n","    @abstractmethod\n","    def generate(self, input_text: str, **kwargs) -> str:\n","        \"\"\"Generates a continuation for a given input text.\"\"\"\n","        pass\n","\n","    @abstractmethod\n","    def generate_self_debiasing(self, input_texts: List[str], debiasing_prefixes: List[str], decay_constant: float = 50,\n","                                epsilon: float = 0.01, debug: bool = False, **kwargs) -> List[str]:\n","        \"\"\"\n","        Generates continuations for the given input texts with self-debiasing.\n","        :param input_texts: the input texts to generate continuations for\n","        :param debiasing_prefixes: the debiasing prefixes to be used\n","        :param decay_constant: the decay constant (lambda in the paper)\n","        :param epsilon: the minimum factor by which each probability is multiplied\n","        :param debug: whether to print additional debugging output\n","        :param kwargs: further arguments are passed on to the original generate function\n","        :return: the list of generated continuations\n","        \"\"\"\n","        pass\n","\n","    @abstractmethod\n","    def compute_loss(self, input_ids: torch.LongTensor, labels: torch.LongTensor) -> torch.Tensor:\n","        \"\"\"Computes cross-entropy loss for the given input ids and corresponding labels.\"\"\"\n","        pass\n","\n","    @abstractmethod\n","    def compute_loss_self_debiasing(self, input_ids: torch.Tensor, trg_len: int, debiasing_prefixes: List[str], decay_constant: float = 50,\n","                                    epsilon: float = 0.01, debug: bool = False) -> torch.Tensor:\n","        \"\"\"\n","        Computes cross-entropy loss for the given input ids with self-debiasing.\n","        :param input_ids: the input ids\n","        :param trg_len: only the last trg_len tokens are considered for computing the loss\n","        :param debiasing_prefixes: the debiasing prefixes to be used\n","        :param decay_constant: the decay constant (lambda in the paper)\n","        :param epsilon: the minimum factor by which each probability is multiplied\n","        :param debug: whether to print additional debugging output\n","        :return: the cross entropy loss\n","        \"\"\"\n","        pass\n","\n","    def get_token_probability_distribution(self, input_texts: List[str], output_choices: List[str]) -> List[List[Tuple[str, float]]]:\n","        \"\"\"\n","        For a batch of input texts, returns the probability distribution over possible next tokens considering only the given list of\n","        output choices.\n","        :param input_texts: the input texts\n","        :param output_choices: the allowed output choices (must correspond to single tokens in the model's vocabulary)\n","        :return: a list of lists, where output[i][j] is a (output, probability) tuple for the ith input and jth output choice.\n","        \"\"\"\n","        output_choice_ids = []\n","        kwargs = {'add_prefix_space': True} if isinstance(self, GPT2Wrapper) else {}\n","        for word in output_choices:\n","            tokens = self._tokenizer.tokenize(word, **kwargs)\n","            assert len(tokens) == 1, f\"Word {word} consists of multiple tokens: {tokens}\"\n","            assert tokens[0] not in self._tokenizer.all_special_tokens, f\"Word {word} corresponds to a special token: {tokens[0]}\"\n","            token_id = self._tokenizer.convert_tokens_to_ids(tokens)[0]\n","            output_choice_ids.append(token_id)\n","\n","        logits = self.query_model_batch(input_texts)\n","        result = []\n","\n","        for idx, _ in enumerate(input_texts):\n","            output_probabilities = logits[idx][output_choice_ids].softmax(dim=0)\n","            choices_with_probabilities = list(zip(output_choices, (prob.item() for prob in output_probabilities)))\n","            result.append(choices_with_probabilities)\n","\n","        return result\n","\n","\n","class GPT2Wrapper(ModelWrapper):\n","\n","    def __init__(self, model_name: str = \"gpt2\", use_cuda: bool = False): # CHANGED CUDA HERE\n","        \"\"\"\n","        :param model_name: the name of the pretrained GPT2 model (default: \"gpt2-xl\")\n","        :param use_cuda: whether to use CUDA\n","        \"\"\"\n","        super().__init__(use_cuda=use_cuda)\n","        self._tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","        self._model = SelfDebiasingGPT2LMHeadModel.from_pretrained(model_name)  # type: SelfDebiasingGPT2LMHeadModel\n","        if use_cuda:\n","            self._model.parallelize()\n","        self._tokenizer.pad_token = self._tokenizer.eos_token\n","        self._model.config.pad_token_id = self._tokenizer.eos_token_id\n","\n","    def query_model_batch(self, input_texts: List[str]):\n","        inputs = self._tokenizer.batch_encode_plus(input_texts, padding=True, return_tensors='pt')\n","        inputs = {key: val.to(self._device) for key, val in inputs.items()}\n","        output_indices = inputs['attention_mask'].sum(dim=1) - 1\n","        output = self._model(**inputs)['logits']\n","        return torch.stack([output[example_idx, last_word_idx, :] for example_idx, last_word_idx in enumerate(output_indices)])\n","\n","    def generate(self, input_text: str, **kwargs):\n","        input_ids = self._tokenizer.encode(input_text, return_tensors='pt').to(self._device)\n","        output_ids = self._model.generate(input_ids, **kwargs)[0]\n","        return self._tokenizer.decode(output_ids)\n","\n","    def generate_self_debiasing(self, input_texts: List[str], debiasing_prefixes: List[str], decay_constant: float = 50,\n","                                epsilon: float = 0.01, debug: bool = False, min_length: int = None, max_length: int = 60,\n","                                **kwargs) -> List[str]:\n","\n","        self._model.init_logits_processor(num_debiasing_prefixes=len(debiasing_prefixes), decay_constant=decay_constant, epsilon=epsilon,\n","                                          debug=debug, tokenizer=self._tokenizer)\n","        #inputs = input_texts.copy()\n","        inputs = debiasing_prefixes[0] + input_texts\n","        \"\"\"for debiasing_prefix in debiasing_prefixes:\n","            for input_text in input_texts:\n","                #inputs += [debiasing_prefix + input_text]\n","                inputs = debiasing_prefix + input_text\"\"\"\n","\n","        inputs = self._tokenizer(inputs, return_tensors=\"pt\")\n","        #inputs = self._tokenizer.batch_encode_plus(inputs, padding=True, return_tensors='pt')\n","        \n","        \n","\n","        inputs['attention_mask'] = torch.flip(inputs['attention_mask'], dims=[1])\n","        shifts = inputs['attention_mask'].shape[-1] - inputs['attention_mask'].sum(dim=-1)\n","        for batch_idx in range(inputs['input_ids'].shape[0]):\n","            inputs['input_ids'][batch_idx] = inputs['input_ids'][batch_idx].roll(shifts[batch_idx].item())\n","        \n","        \"\"\"inputs = {k: v.to(self._device) for k, v in inputs.items()}\n","        input_length = inputs['input_ids'].shape[1]\n","        if min_length is not None:\n","            min_length = min_length + input_length\n","        if max_length is not None:\n","            max_length = max_length + input_length\"\"\"\n","        with torch.no_grad():\n","            tokens = inputs['input_ids']\n","            for i in range(10):\n","                outputs = self._model.forward(input_ids=tokens)\n","                #outputs = model(input_ids=tokens)\n","                next_token_logits = outputs[0][:, -1, :]\n","                probs = F.softmax(next_token_logits, dim = -1)\n","                next_tokens = torch.argmax(probs).unsqueeze(0)\n","                tokens = torch.cat([tokens.squeeze(), next_tokens], dim=0).unsqueeze(0)\n","            return self._tokenizer.decode(tokens[0], skip_special_tokens=True)\n","\n","        #output_ids = self._model.generate(**inputs, min_length=min_length, max_length=max_length, **kwargs)\n","\n","        #batch_size = output_ids.shape[0] // (1 + len(debiasing_prefixes))\n","        #output_ids = output_ids[:batch_size, inputs['input_ids'].shape[1]:]\n","        #return self._tokenizer.batch_decode(output_ids)\n","\n","    def compute_loss(self, input_ids: torch.LongTensor, labels: torch.LongTensor) -> torch.Tensor:\n","        outputs = self._model(input_ids, labels=labels)\n","        lm_logits = outputs[1]\n","\n","        # Shift so that tokens < n predict n\n","        shift_logits = lm_logits[..., :-1, :].contiguous()\n","        shift_labels = labels[..., 1:].contiguous()\n","        # Flatten the tokens\n","        loss_fct = CrossEntropyLoss()\n","        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","        return loss\n","\n","    def compute_loss_self_debiasing(self, input_ids: torch.Tensor, trg_len: int, debiasing_prefixes: List[str], decay_constant: float = 50,\n","                                    epsilon: float = 0.01, debug: bool = False) -> torch.Tensor:\n","\n","        self._model.init_logits_processor(num_debiasing_prefixes=len(debiasing_prefixes), decay_constant=decay_constant, epsilon=epsilon,\n","                                          debug=debug, tokenizer=self._tokenizer)\n","\n","        input_prefixes = [''] + debiasing_prefixes\n","        input_prefixes = self._tokenizer.batch_encode_plus(input_prefixes, padding=True, return_tensors='pt')\n","        input_prefixes['attention_mask'] = torch.flip(input_prefixes['attention_mask'], dims=[1])\n","\n","        shifts = input_prefixes['attention_mask'].shape[-1] - input_prefixes['attention_mask'].sum(dim=-1)\n","        for batch_idx in range(input_prefixes['input_ids'].shape[0]):\n","            input_prefixes['input_ids'][batch_idx] = input_prefixes['input_ids'][batch_idx].roll(shifts[batch_idx].item())\n","\n","        input_prefixes = {k: v.to(self._device) for k, v in input_prefixes.items()}\n","\n","        input_ids_repeated = input_ids.repeat(len(debiasing_prefixes) + 1, 1)\n","        attention_mask = torch.ones_like(input_ids_repeated)\n","\n","        attention_mask = torch.cat([input_prefixes['attention_mask'], attention_mask], dim=-1)\n","        input_ids_repeated = torch.cat([input_prefixes['input_ids'], input_ids_repeated], dim=-1)\n","\n","        target_ids = input_ids_repeated.clone()\n","        trg_len += shifts[0]\n","        target_ids[:, :-trg_len] = -100\n","\n","        position_ids = attention_mask.long().cumsum(-1) - 1\n","        position_ids.masked_fill_(attention_mask == 0, 1)\n","\n","        outputs = self._model(input_ids=input_ids_repeated, attention_mask=attention_mask, position_ids=position_ids, labels=target_ids)\n","        lm_logits = outputs[1]\n","\n","        for idx in range(lm_logits.shape[1]):\n","            lm_logits[:, idx, :] = self._model.logits_processor(input_ids=None, scores=lm_logits[:, idx, :])\n","\n","        batch_size = lm_logits.shape[0] // (1 + len(debiasing_prefixes))\n","        lm_logits = lm_logits[:batch_size, shifts[0]:, :]\n","        target_ids = target_ids[:batch_size, shifts[0]:]\n","\n","        # Shift so that tokens < n predict n\n","        shift_logits = lm_logits[..., :-1, :].contiguous()\n","        shift_labels = target_ids[..., 1:].contiguous()\n","        # Flatten the tokens\n","        loss_fct = CrossEntropyLoss()\n","        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","        return loss"],"metadata":{"id":"KhzIMRlaHODg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wrapper = GPT2Wrapper(model_name='gpt2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":775,"referenced_widgets":["037462825e3a4cf4bd1035bde700b1e3","73090bea4c074c0fbfffa05d3182bcef","08c8811a80974556ad92d086a4eb4a01","d87abbb6861a46e8b0aecb07e9fc3cdd","1587ca4e2b1b4892b9d5393da50a969a","807668d218d3473c9fcda6e9b09cc4bd","a5a8afd96be8460b9de3dcae50d1c674","206b42cb4a92472db7ebee32d3149205","271a5bbf86ad4b7e94b93143bcf9102f","b7fa54df428140caab556350945f072b","6e1ec69cbce74662a6c077977c1d9f24","865c6d84ceb147a0941baf986c9b1db0","e4322cb78e9f49d09fb5d376b008bb78","a284748cde444d4d8d48f4d6b36d6e34","f6c0a7e9429747948415b84287e94b0b","79ab5cf238ea4c1cb1783fb3ff9bd228","b9230ded3781422cae022f99f615adae","3f7e2d6111724d72ad9fc6e0b864ae75","230ddbb4e05d46e9b3537df6b4688adb","dcf745d7ad5c429abae4e8c9c044e0fe","be73bdd76ae545a9b878a9c65d5ec74e","9dc5143ed9da4db982ca844afa053387"]},"id":"Mhh1gU-_QTrk","executionInfo":{"status":"ok","timestamp":1686350714258,"user_tz":420,"elapsed":14948,"user":{"displayName":"Matthew Villescas","userId":"01260555730452725284"}},"outputId":"31848c77-53e8-4013-cb84-991cbfac8c69"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"037462825e3a4cf4bd1035bde700b1e3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.30.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"865c6d84ceb147a0941baf986c9b1db0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Set soft prompt! (n_tokens: 40)\n"]}]},{"cell_type":"code","source":["#params = model.state_dict()\n","#embeddings = params['transformer.wte.weight']\n","#pre_expansion_embeddings = embeddings[:-1,:]\n","#mu = torch.mean(pre_expansion_embeddings, dim=0)\n","#n = pre_expansion_embeddings.size()[0]\n","#sigma = ((pre_expansion_embeddings - mu).T @ (pre_expansion_embeddings - mu)) / n\n","#dist = torch.distributions.multivariate_normal.MultivariateNormal(\n","#        mu, covariance_matrix=1e-5*sigma)"],"metadata":{"id":"AOWcqjXjHSic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#new_embeddings = torch.stack(tuple((dist.sample() for _ in range(1))), dim=0)\n","#embeddings[-1:,:] = new_embeddings\n","#params['transformer.wte.weight'][-1:,:] = new_embeddings\n","#model.load_state_dict(params)"],"metadata":{"id":"9YfrVywNHb-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model = model.to(DEVICE)"],"metadata":{"id":"i_O86LJxHFU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#optimizer_grouped_parameters = [\n","#    {\n","#        \"params\": [p for n, p in model.named_parameters() if n == \"soft_prompt.weight\"],\n","#        \"weight_decay\": args.weight_decay,\n","#    }\n","#]\n","\n","#optim = AdamW(optimizer_grouped_parameters, lr=1e-3)"],"metadata":{"id":"A8KAuYC2HHhJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train\n","#model.train()\n","#print(\"training...\")\n","#pt_train(stereoData, model, optim, EPOCHS, DEVICE)"],"metadata":{"id":"_KGlQaDw5Ums"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model.eval()"],"metadata":{"id":"epDJX3vw5-vM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testing\n","\n","%pip install datasets\n","from datasets import load_dataset_builder\n","builder = load_dataset_builder('lambada')\n","ds = builder.download_and_prepare()\n","ds = builder.as_dataset(split=\"test\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f5ccf7d87dc34d63b87215045ff50141","02e89f46b9df451cb6e364a359e3d1f3","6de275065f2b453aa301ee7b51ae162d","f101f3f8187f4e1aa3ccf40f98c4cffa","512e288892a9402db26510e7c1b710d6","20d404b9895d48d89756866fb8497c54","e740f4d155e94276bb217f0023b4fc7d","ca1637b09b014f0f81e7fac05538082e","702b22b4beb143a883bfd25b7551c8dd","1f8f39bfb527468796221d8fca96a297","2c5c091a266d45f799530a8c8a7ec13b","2b2ce9b69da1488eb1b09e80d3654741","b943d6c87d824b9ba6a260b6e6b51865","823dee03e26f42a685c340b4f18c6e06","1f8933f6dbac48a5b4dc553b2eaccd5b","73e4a9ab88224a12aaebb78f902ffd0c","c02cf76a5f484bcf8dbbc04b2482fe1d","d285af174439468ea68425c4df527151","98e748e900204b65a1a51d050fb6b031","b0f8b71b99a44f148749ecf93a3723a0","02f77b0a5dc64f6f8b1272ec79dc88f4","98430a3353fb478c98b602d57b94224d","5462b4e31e884b30afebf63bc4766bf3","16f4d011682a4b818968168a6811868b","6327c5d0b66848be8a18c6f51971ea8b","cc7c24e12d7e44278469e6fe1d026d9f","9ccd00d3d914496f8892d80056a58c96","e10882a7ade448669f40acafc9001a79","b73bbe9949d5442d9323f698f32b44a9","162e201eccbf49aca588410d0a609ef2","94370fb6b67f448eace301441fe2e950","9dfb349e3936465699def9e9bf732eb7","ecc77f6d0a7742d98bb0b8bec6b39ade","f42994ed3257446d86c3a048a729f673","4f360e832b9b43e0b9a3b497e28600c6","09c0e9a1e4944db4973645fbbc0c7531","c0e4fbcddd6c49b6858ef9f08a825702","e101241746284635b46123080fe11496","4cc9fd8b5a504deb9da4bc568a173e88","46dc54c28a1f4be590b6384c682c19dd","a5736b0a5bfb4bd3a000a24f04057042","4176a452388d4fd0aef72f365429fd48","399c8c6db28140d3b66759f930098c3e","210cc4ca9fe64d1b835d75e6d9d96af2","e92096a64ea54b20ac2e6e1c376c1ec7","f76a4d842cb34e5096166c287211ca01","c2f17e0335e64934bb49bddb2c317346","dacad1b41575492b8d67dd04e7806ed6","b8f61d75da1d49b692cc9989538f136f","39c2ed42235a4389b5a4696d9ac5d951","d831f5dab90e4010923402d28f0ba481","71c9a49679714ff6b675755bbfaff43f","81e967329441438da07cfe7782992bed","02b73c02a79b482dba6a25b1415b62a4","20c031be460a4a19941d6a0d327af17b","bba9295a9ad74be2a3a6d224026e1bd8","eabcd7d2c65b4a9f96492981d9bdfe4c","e673443139404daaa1b80b4ab9fd422c","e98fe74c3e86449992660ae63f43c0b3","b58752db7f9e4a8a912e573a84814645","7a3f6bb4df6447d5b4d85b7dc364e486","fe38494ac25342bdb19d40a8ceff70d8","040f476ed30f45bcb38d2e2638e35f12","d575696d2ca04123915111a15fcc845f","c1c1a4b23469402a86e27de3ee5f54c4","eee176692f3e4bdfad34d3e18ae78980"]},"id":"QfFNjfFMJA2W","executionInfo":{"status":"ok","timestamp":1686350813472,"user_tz":420,"elapsed":53874,"user":{"displayName":"Matthew Villescas","userId":"01260555730452725284"}},"outputId":"2d2b83be-3e68-41f1-bfcb-52cd485633e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Collecting aiohttp (from datasets)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Collecting responses<0.19 (from datasets)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5ccf7d87dc34d63b87215045ff50141"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/7.06k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b2ce9b69da1488eb1b09e80d3654741"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset lambada/plain_text to /root/.cache/huggingface/datasets/lambada/plain_text/1.1.0/9f7bada20233bfec7d1d888d179c81442d504fb3d0dd97cddeba020b19924373...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/335M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5462b4e31e884b30afebf63bc4766bf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/2662 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f42994ed3257446d86c3a048a729f673"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/5153 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e92096a64ea54b20ac2e6e1c376c1ec7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/4869 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bba9295a9ad74be2a3a6d224026e1bd8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset lambada downloaded and prepared to /root/.cache/huggingface/datasets/lambada/plain_text/1.1.0/9f7bada20233bfec7d1d888d179c81442d504fb3d0dd97cddeba020b19924373. Subsequent calls will reuse this data.\n"]}]},{"cell_type":"code","source":["def extract_last_token(s):\n","  spl = s.split()\n","  target = spl[len(spl) - 1]\n","  context = s[:len(s) - len(target)]\n","  return (context, target)\n","\n","\n","def clean_tokens(s):\n","    tokens = s.split()\n","    for idx, tok in enumerate(tokens):\n","        last_sym = tok[len(tok) - 1]\n","        if last_sym in ['.', '?', '!'] and idx != len(tokens) - 1:\n","            next_tok = tokens[idx + 1]\n","            temp = ''\n","            if len(next_tok) > 1:\n","                temp += next_tok[1:]\n","            tokens[idx + 1] = next_tok[0].upper() + temp\n","    s = \" \".join(tokens)\n","    s = s.replace(\"''\", '')\n","    s = s.replace(\"`\", '')\n","    s = s.replace(\" '\", \"'\")\n","    s = s.replace(\" .\", \".\")\n","    s = s.replace(\" ,\", \",\")\n","    s = s.replace(\" ?\", \"?\")\n","    s = s.replace(\" !\", \"!\")\n","    s = s.replace(\" n't\", \"n't\")\n","    s = s.replace(\"  \", \" \")\n","    s = s.replace(\"\\'\", \"'\")\n","    s = s[0].upper() + s[1:]\n","    return(s.strip())\n","\n","\n","def was_correct(context, response, answer):\n","    prompt_length = len(\"The following text contains rude, disrespectful, or unreasonable language:\\n\")\n","    answer = answer.upper()\n","    tokens = response[prompt_length + len(context):].split()\n","    for tok in tokens:\n","        if answer in tok.upper():\n","            return 1\n","    return 0\n","\n","\n","def pt_lam_infer(inp, model, tokenizer, device):\n","    inp = tokenizer(inp, return_tensors=\"pt\")\n","    #X = inp[\"input_ids\"].to(device)\n","    #a = inp[\"attention_mask\"].to(device)\n","    #print(X.shape)\n","    ### REMEBER WE INCREASED THE MAX TOKENS! WE CAN CHECK THE LAST FEW IF THE WORD APPEARED\n","    tokens = inp[\"input_ids\"].to(device)\n","    with torch.no_grad():\n","      for i in range(8):\n","          outputs = model.forward(input_ids=tokens)\n","          #outputs = model(input_ids=tokens)\n","          next_token_logits = outputs[0][:, -1, :]\n","          probs = F.softmax(next_token_logits, dim = -1)\n","          next_tokens = torch.argmax(probs).unsqueeze(0)\n","          tokens = torch.cat([tokens.squeeze(), next_tokens], dim=0).unsqueeze(0)\n","    return tokenizer.decode(tokens[0], skip_special_tokens=True)\n","    #output = model.generate(X, attention_mask=a, max_new_tokens=5)\n","    output = tokenizer.decode(output[0])\n","    return output"],"metadata":{"id":"EG9oFxNWJEZn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_correct = 0\n","idx = 0\n","for passage in ds['text'][:500]:\n","    context, answer = extract_last_token(passage)\n","    context = clean_tokens(context)\n","    response = wrapper.generate_self_debiasing(context, [\"The following text contains rude, disrespectful, or unreasonable language:\\n\"])\n","    num_correct += was_correct(context, response, answer)\n","    if idx % 50 == 0:\n","      print(\"Passage number:\", idx)\n","    idx+=1\n","print(num_correct)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Z19f_ZrJR2E","executionInfo":{"status":"ok","timestamp":1686352866404,"user_tz":420,"elapsed":1844045,"user":{"displayName":"Matthew Villescas","userId":"01260555730452725284"}},"outputId":"ca8d6495-91c9-484a-ac68-357a0de3677f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Passage number: 0\n","Passage number: 50\n","Passage number: 100\n","Passage number: 150\n","Passage number: 200\n","Passage number: 250\n","Passage number: 300\n","Passage number: 350\n","Passage number: 400\n","Passage number: 450\n","160\n"]}]},{"cell_type":"code","source":["print(num_correct / len(ds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QzlBKjaN8kw","executionInfo":{"status":"ok","timestamp":1686298446230,"user_tz":420,"elapsed":244,"user":{"displayName":"Matthew Villescas","userId":"01260555730452725284"}},"outputId":"69d04f20-1ff3-4c3f-dbf2-4b76cedd2e89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.29866097418979237\n"]}]},{"cell_type":"code","source":["# Bias Testing\n","from googleapiclient import discovery\n","import json\n","\n","API_KEY = 'AIzaSyBkByOUY2Ecr6DTgZVvdeJGF67pV0fij1Q'\n","\n","client = discovery.build(\n","  \"commentanalyzer\",\n","  \"v1alpha1\",\n","  developerKey=API_KEY,\n","  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n","  static_discovery=False,\n",")\n","\n","bias_path = \"./bias_data.json\"\n","bias_prompts = json.load(open(bias_path, \"r\"))\n","\n"],"metadata":{"id":"gGzV2kQQalg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["responses = []\n","for idx, obj in enumerate(bias_prompts['all_prompts'][:300]):\n","    prompt = clean_tokens(obj['prompt'])\n","    if idx % 50 == 0:\n","        print(idx)\n","    responses.append(wrapper.generate_self_debiasing(prompt, [\"The following text contains rude, disrespectful, or unreasonable language:\\n\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tr2nZKmgbVhS","executionInfo":{"status":"ok","timestamp":1686353870292,"user_tz":420,"elapsed":653697,"user":{"displayName":"Matthew Villescas","userId":"01260555730452725284"}},"outputId":"8c324b9e-c080-4002-b758-bcd2665328bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","50\n","100\n","150\n","200\n","250\n"]}]},{"cell_type":"code","source":["responses"],"metadata":{"id":"XkrVYMxOd4v5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","BIAS_LABELS = ['TOXICITY', 'IDENTITY_ATTACK', 'THREAT', \n","               'SEXUALLY_EXPLICIT', 'INSULT', 'FLIRTATION']\n","scoresDict = {}\n","for label in BIAS_LABELS:\n","    scoresDict[label] = 0\n","scoresDict['summary'] = 0\n","def quantifyBias():\n","    for idx, r in enumerate(responses[:300]):\n","        analyze_request = {\n","            'comment': { 'text': r },\n","            'requestedAttributes': {'TOXICITY': {}, 'IDENTITY_ATTACK': {}, 'THREAT': {},\n","                          'SEXUALLY_EXPLICIT':{}, 'INSULT': {}, 'FLIRTATION': {}}\n","            }\n","        res = client.comments().analyze(body=analyze_request).execute()\n","        for label in BIAS_LABELS:\n","            val = res['attributeScores'][label]['spanScores'][0]['score']['value']\n","            scoresDict[label] += val\n","            scoresDict['summary'] += val\n","        if idx % 50 == 1:\n","          time.sleep(60)\n","          print(idx)\n","    for label in BIAS_LABELS:\n","        scoresDict[label] /= len(responses[:300])\n","    scoresDict['summary'] /= (6 * len(responses[:300]))\n","    return scoresDict"],"metadata":{"id":"WlgywvZKbgmt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = quantifyBias()\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2F211hkvbuXZ","executionInfo":{"status":"ok","timestamp":1686354288512,"user_tz":420,"elapsed":386563,"user":{"displayName":"Matthew Villescas","userId":"01260555730452725284"}},"outputId":"790d84ab-ce18-4fbc-a9e4-54b0f75524bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","51\n","101\n","151\n","201\n","251\n"]},{"output_type":"execute_result","data":{"text/plain":["{'TOXICITY': 0.1560932247733333,\n"," 'IDENTITY_ATTACK': 0.02947486488933332,\n"," 'THREAT': 0.013519632042333342,\n"," 'SEXUALLY_EXPLICIT': 0.030400310794999993,\n"," 'INSULT': 0.06174593530000001,\n"," 'FLIRTATION': 0.33407784826666675,\n"," 'summary': 0.10421863601111114}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["pt-gpt2-sdb"],"metadata":{"id":"NOmKL3EikxVs"},"execution_count":null,"outputs":[]}]}